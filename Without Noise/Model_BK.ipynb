{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imgs, train_lbls), (test_imgs, test_lbls) = tf.keras.datasets.cifar10.load_data()\n",
    "train_imgs = train_imgs/ 255.0\n",
    "test_imgs = test_imgs/ 255.0\n",
    "\n",
    "num_classes = 10\n",
    "train_lbls = np.squeeze(keras.utils.to_categorical(train_lbls, num_classes))\n",
    "test_lbls = np.squeeze(keras.utils.to_categorical(test_lbls, num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispaly of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (train_imgs[400].squeeze())\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model 'BK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape= (32,32,3)),\n",
    "    tf.keras.layers.Conv2D(32,5, strides = (1, 1), padding='same', use_bias=True,activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2),(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, 5, strides = (1, 1), padding='same', use_bias=True,activation = 'relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(data_format='channels_last'),\n",
    "    tf.keras.layers.Dense(10, activation = 'sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr=0.001\n",
    "    decay_rate = 0.01\n",
    "    decay_step = 30\n",
    "    lrate = initial_lr * decay_rate ** (epoch/decay_step)\n",
    "    print(\"learning_rate\")\n",
    "    print(lrate)\n",
    "    return lrate\n",
    "\n",
    "Adam = tf.keras.optimizers.Adam(lr=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = Adam, metrics=['accuracy'])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With Noise\n",
    "history = model.fit(train_imgs, train_lbls, batch_size=128, epochs=100, validation_split=0.1, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without Noise\n",
    "model.evaluate(test_imgs, test_lbls)\n",
    "\n",
    "#With Noise\n",
    "model.evaluate(noise_test_imgs, test_lbls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(n):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(test_imgs[i])\n",
    "    plt.title(\"Lable:{}\\nPredicted:{}\".format(test_lbls[i],np.argmax(predictions[i])))\n",
    "    plt.axis='off'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model and the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Model_BK.h5') #Depending on the level of noise and the model, name is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = []\n",
    "ground_truth_values = []\n",
    "for i in range(len(test_imgs)):\n",
    "    model_predictions.append(np.argmax(predictions[i]))\n",
    "      ground_truth_values.append(np.argmax(test_lbls[i]))\n",
    "\n",
    "\n",
    "correct_prediction = [i if i==j else 0 for i, j in zip(model_predictions, ground_truth_values)]\n",
    "import pandas as pd\n",
    "prediction_df = pd.DataFrame(correct_prediction, columns=['result']).to_csv('BK_1_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
